{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, RecursiveJsonSplitter\n",
    "from langchain_community.document_loaders import TextLoader, JSONLoader\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains.conversational_retrieval.base import ConversationalRetrievalChain\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# from fastapi import FastAPI\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# from langchain.schema import Document\n",
    "# from langchain.prompts import PromptTemplate\n",
    "# from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/data.json', 'r') as file:\n",
    "#     workshops_data = json.load(file)\n",
    "\n",
    "# workshop_documents = []\n",
    "\n",
    "# for workshop in workshops_data:\n",
    "#     content = json.dumps(workshop, indent=2)\n",
    "    \n",
    "#     doc = Document(\n",
    "#         page_content=content,\n",
    "#         metadata={\n",
    "#             \"title\": workshop[\"title\"],\n",
    "#             \"duration\": workshop[\"duration\"],\n",
    "#             \"max_participants\": workshop[\"max_participants\"]\n",
    "#         }\n",
    "#     )\n",
    "#     workshop_documents.append(doc)\n",
    "\n",
    "# workshop_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "open_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not open_api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data/data.txt'}, page_content='Azercell is the only company in Azerbaijan and CIS region which has been awarded Platinum'),\n",
       " Document(metadata={'source': 'data/data.txt'}, page_content='and CIS region which has been awarded Platinum Certificate of International “Investors in People”'),\n",
       " Document(metadata={'source': 'data/data.txt'}, page_content='of International “Investors in People” Standard. The mobile operator is the only company in the'),\n",
       " Document(metadata={'source': 'data/data.txt'}, page_content='The mobile operator is the only company in the country to receive Gold Award in nominations of'),\n",
       " Document(metadata={'source': 'data/data.txt'}, page_content='country to receive Gold Award in nominations of \"Company of the Year\" and “The Most Innovative'),\n",
       " Document(metadata={'source': 'data/data.txt'}, page_content='of \"Company of the Year\" and “The Most Innovative Company of the Year” from the International'),\n",
       " Document(metadata={'source': 'data/data.txt'}, page_content='Company of the Year” from the International Business Award  STEVIE.')]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TextLoader(\"data/data.txt\", encoding=\"utf-8\")\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(documents)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL AND VECTOR DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generative_model = OpenAI(\n",
    "#     model=\"gpt-3.5-turbo-instruct\",\n",
    "#     temperature=0\n",
    "# ) \n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "vector_store = FAISS.from_documents(docs, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUSTOM PROMPT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    You are a helpful AI assistant. \n",
    "    Use the following context to answer the user's question in a concise manner. \n",
    "    If you're not sure, say \"I am not sure based on the data provided.\"\n",
    "    \n",
    "    Context: \n",
    "    {context}\n",
    "    \n",
    "    Question: \n",
    "    {question}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query1 = \"what is the duration of the AI Chatbot Workshop?\"\n",
    "# query1_answer = vector_store.similarity_search(query1)\n",
    "# query1_answer\n",
    "# query1_answer[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RETREIVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": custom_prompt\n",
    "    }, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI assistant. \n",
      "    Use the following context to answer the user's question in a concise manner. \n",
      "    If you're not sure, say \"I am not sure based on the data provided.\"\n",
      "    \n",
      "    Context: \n",
      "    and CIS region which has been awarded Platinum Certificate of International “Investors in People”\n",
      "\n",
      "Company of the Year” from the International Business Award  STEVIE.\n",
      "\n",
      "country to receive Gold Award in nominations of \"Company of the Year\" and “The Most Innovative\n",
      "\n",
      "Azercell is the only company in Azerbaijan and CIS region which has been awarded Platinum\n",
      "    \n",
      "    Question: \n",
      "    what is the duration of the AI Chatbot Workshop?\n",
      "    \n",
      "    Answer:\n",
      "    \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain.invoke({\"query\": \"what is the duration of the AI Chatbot Workshop?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is the duration of the AI Chatbot Workshop?',\n",
       " 'result': 'I am not sure based on the data provided.'}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
